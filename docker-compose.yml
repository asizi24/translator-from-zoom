# =============================================================================
# Docker Compose - GCP Production Configuration
# =============================================================================
# Optimized for: n2-highmem-8 (8 vCPU, 64GB RAM)
# 
# Key Features:
# - Large-v3 Whisper model for maximum accuracy
# - Cost-safe restart policy (on-failure:5)
# - 16GB memory limit for high-mem instance
# =============================================================================

services:
  web:
    build:
      context: .
      args:
        # Build with the largest model baked in for speed
        WHISPER_MODEL: large-v3
    container_name: transcription_app
    
    # Critical for cost safety: Don't restart forever on errors
    restart: on-failure:5
    
    deploy:
      resources:
        limits:
          memory: 16G    # High-Mem instance optimization
          cpus: '6.0'
        reservations:
          memory: 4G
          cpus: '2.0'

    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

    volumes:
      - ./downloads:/app/downloads
      - ./uploads:/app/uploads
      - huggingface_cache:/home/appuser/.cache/huggingface

    env_file:
      - .env

    environment:
      - WHISPER_MODEL=large-v3
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - HF_TOKEN=${HF_TOKEN}
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
      - CPU_THREADS=8
      - AUTO_SHUTDOWN=true
      - IDLE_TIMEOUT_MINUTES=30
      - SHUTDOWN_DRY_RUN=${SHUTDOWN_DRY_RUN:-true}
      - FLASK_ENV=production
      
    ports:
      - "5000:5000"

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 180s

  nginx:
    image: nginx:alpine
    container_name: nginx_proxy
    restart: unless-stopped
    
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"
    
    ports:
      - "80:80"
    
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    
    depends_on:
      web:
        condition: service_started

volumes:
  huggingface_cache:
    name: transcription_hf_cache
